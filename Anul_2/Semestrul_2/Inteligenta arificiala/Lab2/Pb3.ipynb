{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572d29fa-2858-4d1c-bc96-64a0fab15758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se da un fisier care contine un text (format din mai multe propozitii) in limba romana - a se vedea fisierul ”data/texts.txt”. Se cere sa se determine si sa se vizualizeze:\n",
    "\n",
    "# - numarul de propozitii din text;\n",
    "# - numarul de cuvinte din text\n",
    "# - numarul de cuvinte diferite din text\n",
    "# - cel mai scurt si cel mai lung cuvant (cuvinte)\n",
    "# - textul fara diacritice\n",
    "# - sinonimele celui mai lung cuvant din text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04006a8d-6261-43bd-b98c-a53b9aba36c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numar propozitii: 10\n"
     ]
    }
   ],
   "source": [
    "# numarul de propozitii din text;\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "with open('data/text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print('Numar propozitii:', len(sent_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031548cb-07f9-4791-84fb-9d09341ea17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numar cuvinte: 155\n"
     ]
    }
   ],
   "source": [
    "# numarul de cuvinte din text\n",
    "words = word_tokenize(text)\n",
    "words=[word.lower() for word in words if word.isalpha()]\n",
    "print('Numar cuvinte:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33130b9-f8a2-4593-b67e-90c336ace103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuvinte diferite: 88\n"
     ]
    }
   ],
   "source": [
    "# numarul de cuvinte diferite din text\n",
    "from nltk.probability import FreqDist\n",
    "print('Cuvinte diferite:', len(FreqDist(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08827c45-257b-4efa-bcf3-f82d657b3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cel mai scurt cuvant:  o\n",
      "Cel mai lung cuvant:  laboratoarele\n"
     ]
    }
   ],
   "source": [
    "# cel mai scurt si cel mai lung cuvant (cuvinte)\n",
    "print('Cel mai scurt cuvant: ', min(words, key=len))\n",
    "max_word = max(words, key=len)\n",
    "print('Cel mai lung cuvant: ', max_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3f91a1-d6ec-4aa1-82b4-371e90c82325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesaj de informare: \n",
      "Cursul si laboratoarele de Inteligenta Artificiala vor fi o \n",
      "provocare pentru toti. Suntem convinsi ca veti realiza proiecte \n",
      "foarte interesante. Va incurajam sa adresati intrebari atunci \n",
      "cand ceva nu e clar, atat in mod live, cat si folosind platforma \n",
      "Teams, canalul \"general\". \n",
      "Daca ati citit pana aici, va rugam sa lasati un mesaj pe canalul \n",
      "general cu textul \"Am citit textul pentru problema 3\". \n",
      "Mesaj de informare generat de ChatGPT:\n",
      "Stimati cursanti,\n",
      "Suntem incantati sa va avem in echipa noastra pentru Cursul si \n",
      "laboratoarele de Inteligenta Artificiala. Aceasta experienta va \n",
      "fi o adevarata provocare, dar suntem convinsi ca veti realiza \n",
      "proiecte extrem de interesante.\n",
      "Va incurajam sa fiti activi si sa adresati intrebari atunci cand \n",
      "ceva nu este clar. Fie ca este vorba de o discutie in timp real \n",
      "sau prin intermediul platformei Teams, canalul \"general\", suntem \n",
      "aici sa va sprijinim.\n",
      "Succes si sa inceapa aventura AI!\n",
      "Cu consideratie, Echipa de Inteligenta Artificiala\n"
     ]
    }
   ],
   "source": [
    "# textul fara diacritice\n",
    "from unidecode import unidecode\n",
    "print(unidecode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef57e2a7-4b45-4d10-8288-2676e7db70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sinonimele celui mai lung cuvant din text\n",
    "from nltk.corpus import wordnet \n",
    "# from nltk.stem import PorterStemmer\n",
    "# # nltk.download('omw-1.4')\n",
    "# stemmer = PorterStemmer()\n",
    "# synonyms = [] \n",
    "\n",
    "# print(stemmer.stem(\"laboratory\"))\n",
    "\n",
    "# for syn in wordnet.synsets(\"laborator\", lang='ron'): \n",
    "#     for l in syn.lemmas('ron'): \n",
    "#         synonyms.append(l.name()) \n",
    "\n",
    "# print(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501e3ddd-9f5b-4f13-87d6-b802484e2f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'laborator de cercetare', 'teren_testare', 'laborator', 'cercetare_laborator', 'laborator_știință'}\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "longest_word_en_lst = GoogleTranslator(source='auto', target='en').translate(max_word)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "tokens = word_tokenize(longest_word_en_lst)\n",
    "output = \"\"\n",
    "if len(tokens) != 1:\n",
    "    for words in tokens:\n",
    "        if not words in stop_words:\n",
    "            output= words\n",
    "    \n",
    "synonyms = []\n",
    "for synset in wordnet.synsets(output):\n",
    "    for lemma in synset.lemmas():\n",
    "        synonyms.append(GoogleTranslator(source='auto', target='ro').translate(lemma.name()))\n",
    "\n",
    "print(set(synonyms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1a67aac-140d-4274-b7d3-7d431bdb1668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep_translator\n",
      "  Obtaining dependency information for deep_translator from https://files.pythonhosted.org/packages/38/3f/61a8ef73236dbea83a1a063a8af2f8e1e41a0df64f122233938391d0f175/deep_translator-1.11.4-py3-none-any.whl.metadata\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deep_translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deep_translator) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2024.2.2)\n",
      "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.3 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 30.7/42.3 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 42.3/42.3 kB 516.9 kB/s eta 0:00:00\n",
      "Installing collected packages: deep_translator\n",
      "Successfully installed deep_translator-1.11.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install deep_translator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
