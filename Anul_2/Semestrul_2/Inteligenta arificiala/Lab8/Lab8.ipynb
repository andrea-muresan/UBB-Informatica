{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c71ecb44-8e13-4247-ab15-0c718ebe35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import markovify\n",
    "from datasets import load_dataset\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6daccf-57c1-4017-aa9d-00f8ed3aa26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generare în limba română: Implementați un sistem care transformă un text (corpus) într-un lanț Markov și \n",
    "# folosiți-l pentru a generare un proverb sau o poezie în limba română (folosiți fișierele proverbRo.txt sau poezieRo.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe173e1c-a889-4a08-8051-a4cb681865d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianta 1 – Implementați un lanț Markov cu o singură stare sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc96ebd8-0400-49ca-a83e-c418a92fda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text\n",
    "with open('data/proverbe.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba7bdf4d-a134-464c-ac41-0fd0c618c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov chain\n",
    "words = text.split()\n",
    "chain = {}\n",
    "for i in range(len(words) - 1):\n",
    "    current_word = words[i]\n",
    "    next_word = words[i + 1]\n",
    "    if current_word in chain:\n",
    "        chain[current_word].append(next_word)\n",
    "    else:\n",
    "        chain[current_word] = [next_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f84f82e-b051-4bed-b154-c10402c36232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proverb:\n",
      "Pe cine nu locul nu iese soarele pe.\n"
     ]
    }
   ],
   "source": [
    "# Generate a proverb using the Markov chain\n",
    "length = 8\n",
    "current_word = random.choice(list(chain.keys())).strip('.')\n",
    "generated_text = [current_word]\n",
    "for _ in range(length - 1):\n",
    "    if current_word in chain:\n",
    "        next_word = random.choice(chain[current_word])\n",
    "        next_word = next_word.strip('.')\n",
    "        generated_text.append(next_word)\n",
    "        current_word = next_word\n",
    "    else:\n",
    "        break\n",
    "generated_text[-1] += '.'\n",
    "proverb = ' '.join(generated_text)\n",
    "\n",
    "print(\"Proverb:\")\n",
    "print(proverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddb59ec3-1fbe-4dae-b13d-b461bf05c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianta 2 – Implementați un lanț Markov cu n-stări"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d3c242a-e4b4-49b6-ad18-816a859de8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text\n",
    "with open('data/proverbe.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32b3834e-0cdf-451b-9e8d-c3d236682288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov chain n states\n",
    "n = 4\n",
    "\n",
    "words = text.split()\n",
    "chain = {}\n",
    "for i in range(len(words) - n):\n",
    "    # Extract the current state\n",
    "    current_state = tuple(words[i:i + n])\n",
    "    # Get the next word after the current state\n",
    "    next_word = words[i + n]\n",
    "    # Update the chain dictionary with the current state and next word\n",
    "    if current_state in chain:\n",
    "        chain[current_state].append(next_word)\n",
    "    else:\n",
    "        chain[current_state] = [next_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9cba1a4-c631-49a5-96a5-f061c6f1e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proverb\n",
      "zice popa Nu haina il face pe om Nu.\n"
     ]
    }
   ],
   "source": [
    "# Generate using Markov chain - n states\n",
    "length = 9\n",
    "current_state = random.choice(list(chain.keys()))\n",
    "generated_text = list(current_state)\n",
    "for _ in range(length - n):\n",
    "    if current_state in chain:\n",
    "        # Randomly select the next word from the list of values associated with the current state\n",
    "        next_word = random.choice(chain[current_state])\n",
    "        generated_text.append(next_word)\n",
    "        current_state = tuple(generated_text[-n:])\n",
    "    else:\n",
    "        break\n",
    "generated_text = [word.strip('.') for word in generated_text]\n",
    "if not generated_text[-1].endswith('.'):\n",
    "    generated_text[-1] += '.'\n",
    "proverb = ' '.join(generated_text)\n",
    "\n",
    "\n",
    "print(\"Proverb\")\n",
    "print(proverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a0bce17-3d3a-4b40-b8a2-91480f4d2a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generare în limba engleză:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b0acd55-b462-464b-a61e-f65c8c5dba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Folosiți biblioteca markovify (sau implementarea voastră de la problema 1) pentru a genera o strofă de poezie în limba engleză folosind unul din următoarele corpus-uri (sau orice altă sursă găsiți voi):\n",
    "\n",
    "# https://huggingface.co/datasets/biglam/gutenberg-poetry-corpus\n",
    "# https://github.com/tnhaider/english-gutenberg-poetry\n",
    "# https://www.shakespeares-sonnets.com/all.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea8e9961-18b5-46f3-836c-c71b98d220c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the poetry dataset\n",
    "dataset = load_dataset(\"biglam/gutenberg-poetry-corpus\")\n",
    "\n",
    "poetry_text = \"\"\n",
    "if \"train\" in dataset:\n",
    "    poetry_data = dataset[\"train\"]\n",
    "    poetry_text = \"\\n\".join(poetry_data[\"line\"])\n",
    "else:\n",
    "    print(\"Failed to load data\")\n",
    "    poetry_text = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39911067-a6ec-4206-8822-0d3ec11353fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Markov model\n",
    "if poetry_text:\n",
    "    text_model = markovify.NewlineText(poetry_text, state_size=2)\n",
    "else:\n",
    "    print(\"Failed to generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52cef086-d82e-4747-aa9b-95d19851a24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "From the new year come,\n",
      "With a pale, green moon is a-bloom in the sombre rafters, that round him first\n",
      "Bright hopes, that erst by Cato's foot was moved with wrath,.\n"
     ]
    }
   ],
   "source": [
    "# Generate a poetry\n",
    "gen_poetry = \"\"\n",
    "\n",
    "gen_poetry = '\\n'.join([text_model.make_sentence(tries=100) for _ in range(3)])  \n",
    "if not gen_poetry.endswith((\".\", \"!\", \"?\", \";\")):\n",
    "    gen_poetry += \".\"\n",
    "\n",
    "print(\"Generated:\")\n",
    "print(gen_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4afc8a9f-08e8-44a8-a1b0-71439b53100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Calculați emoția textului generat, puteți folosi una din următoarele resurse:\n",
    "\n",
    "# Natural Language Toolkit (nltk) SentimentIntensityAnalyzer\n",
    "# TextBlob sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adf70123-98eb-4561-b454-c963e4ca3a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity: -0.80078125\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis\n",
    "blob = TextBlob(text)\n",
    "sentiment_polarity = blob.sentiment.polarity\n",
    "print(\"Sentiment Polarity:\", sentiment_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "460de709-2615-4499-aa20-8d74dfc6a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Pentru a adresa limitările de creativitate în poezia generată înlocuiți aleator cuvinte cu sinonime. \n",
    "# Se cere ca sinonimele să fie obținute folosind embedding-uri. (i.e. Cuvântul ales e transformat în forma sa \n",
    "# embedded și se alege embedding-ul cel mai apropiat care este convertit la string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba551bf6-9d40-44d9-aa19-3ed3b21df44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "# Încărcăm modelul spaCy cu embeddings\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "800c5153-5fc2-4dca-ba71-855f0bc17841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synonym(word):\n",
    "    last_similarity = 0.3\n",
    "    synonym = None\n",
    "    word_embedding = nlp(word).vector\n",
    "    \n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            lemma_embedding = nlp(lemma.name()).vector\n",
    "            if np.count_nonzero(word_embedding) == 0 or np.count_nonzero(lemma_embedding) == 0:\n",
    "                continue\n",
    "            similarity = np.dot(word_embedding, lemma_embedding) / (np.linalg.norm(word_embedding) * np.linalg.norm(lemma_embedding))\n",
    "            if similarity > last_similarity:\n",
    "                last_similarity = similarity\n",
    "                synonym = lemma.name()\n",
    "    \n",
    "    return synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a27b53a-2e03-4c13-ae16-44783808c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_synonyms(poetry):\n",
    "    new_poetry = []\n",
    "    for verse in poetry.split('\\n'):\n",
    "        for word in verse.split():\n",
    "            if wordnet.synsets(word):\n",
    "                synonym = find_synonym(word)\n",
    "                new_poetry.append(synonym)\n",
    "            else:\n",
    "                new_poetry.append(word)\n",
    "            new_poetry.append(\" \")\n",
    "        new_poetry.append('\\n')\n",
    "    return \"\".join(new_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab82e9c6-35ae-414e-a5ed-6e60e2b104f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetry:\n",
      "From the new year come,\n",
      "With a pale, green moon is a-bloom in the sombre rafters, that round him first\n",
      "Bright hopes, that erst by Cato's foot was moved with wrath,.\n",
      "\n",
      "New poetry:\n",
      "From the new year come, \n",
      "With a pale, green moon be a-bloom in the sombre rafters, that round him first \n",
      "bright hopes, that erst by Cato's foot be moved with wrath,. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Poetry:\")\n",
    "print(gen_poetry)\n",
    "\n",
    "new_poetry = replace_with_synonyms(gen_poetry)\n",
    "\n",
    "print(\"\\nNew poetry:\")\n",
    "print(new_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38c6a08a-96d2-4020-80c0-99f548ffc8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Salvați poezia care vi se pare cea mai reușită si trimiteti-o unui prieten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdf68ae1-e81d-4ea5-85eb-9c33b590fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. Calculați metrica BLEU (Bilingual Evaluation Understudy Score) pentru poezia aleasă"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "259981c8-11ba-4f33-9be3-64c568e7cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_generator(sentence,n= 2,n_gram= False):\n",
    "    '''\n",
    "    N-Gram generator with parameters sentence\n",
    "    n is for number of n_grams\n",
    "    The n_gram parameter removes repeating n_grams \n",
    "    '''\n",
    "    sentence = sentence.lower() # converting to lower case\n",
    "    sent_arr = np.array(sentence.split()) # split to string arrays\n",
    "    length = len(sent_arr)\n",
    "\n",
    "    word_list = []\n",
    "    for i in range(length+1):\n",
    "        if i < n:\n",
    "            continue\n",
    "        word_range = list(range(i-n,i))\n",
    "        s_list = sent_arr[word_range]\n",
    "        string = ' '.join(s_list) # converting list to strings\n",
    "        word_list.append(string) # append to word_list\n",
    "        if n_gram:\n",
    "            word_list = list(set(word_list))\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7782ac22-8d10-4ff7-bc1a-04b8d248c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6773811491339269\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter  # Add this line\n",
    "import math\n",
    "\n",
    "def bleu_score(original,machine_translated):\n",
    "    '''\n",
    "    Bleu score function given a orginal and a machine translated sentences\n",
    "    '''\n",
    "    mt_length = len(machine_translated.split())\n",
    "    o_length = len(original.split())\n",
    "\n",
    "    # Brevity Penalty \n",
    "    if mt_length>o_length:\n",
    "        BP=1\n",
    "    else:\n",
    "        penality=1-(mt_length/o_length)\n",
    "        BP=np.exp(penality)\n",
    "\n",
    "    # Clipped precision\n",
    "    clipped_precision_score = []\n",
    "    for i in range(1, 5):\n",
    "        original_n_gram = Counter(n_gram_generator(original,i))\n",
    "        machine_n_gram = Counter(n_gram_generator(machine_translated,i))\n",
    "\n",
    "        c = sum(machine_n_gram.values())\n",
    "        for j in machine_n_gram:\n",
    "            if j in original_n_gram:\n",
    "                if machine_n_gram[j] > original_n_gram[j]:\n",
    "                    machine_n_gram[j] = original_n_gram[j]\n",
    "            else:\n",
    "                machine_n_gram[j] = 0\n",
    "\n",
    "        #print (sum(machine_n_gram.values()), c)\n",
    "        clipped_precision_score.append(sum(machine_n_gram.values())/c)\n",
    "\n",
    "    #print (clipped_precision_score)\n",
    "\n",
    "    weights =[0.25]*4\n",
    "\n",
    "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
    "    s = BP * math.exp(math.fsum(s))\n",
    "    return s\n",
    "\n",
    "original = \"\"\"\n",
    "My last thought is yet unknown;\n",
    "And venerable walls against the dusty floor\n",
    "To smile, to greet the dewy spring;\n",
    "\"\"\"\n",
    "machine_translated = \"\"\"\n",
    "My last thought remains unknown;\n",
    "And venerable walls against the dusty floor\n",
    "Smile, greeting the dewy spring;\n",
    "\"\"\"\n",
    "\n",
    "print (bleu_score(original, machine_translated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898c70e-1d2d-48e3-bbac-c88cee990c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
